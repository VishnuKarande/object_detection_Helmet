{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNs+QUZa4jnQoLbkiHsFrcA"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","source":["!pip install tensorflow-gpu"],"metadata":{"id":"SvWbU8kl0FJo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[" import tensorflow as tf"],"metadata":{"id":"Z02L5Yy90NU_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(tf.__version__)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jvPjhqvx0lLQ","executionInfo":{"status":"ok","timestamp":1675846201764,"user_tz":-330,"elapsed":10,"user":{"displayName":"Vishnu Karande","userId":"00058094659799713799"}},"outputId":"ff47bb70-7dcf-499f-ad6b-7648366b2a8f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2.9.2\n"]}]},{"cell_type":"code","source":["!git clone https://github.com/tensorflow/models.git"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oVWkS8ll0quH","executionInfo":{"status":"ok","timestamp":1675846247488,"user_tz":-330,"elapsed":43511,"user":{"displayName":"Vishnu Karande","userId":"00058094659799713799"}},"outputId":"8b9bdf52-5ffb-4afb-d602-10e6086d0f1f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'models'...\n","remote: Enumerating objects: 81176, done.\u001b[K\n","remote: Counting objects: 100% (40/40), done.\u001b[K\n","remote: Compressing objects: 100% (33/33), done.\u001b[K\n","remote: Total 81176 (delta 19), reused 14 (delta 7), pack-reused 81136\u001b[K\n","Receiving objects: 100% (81176/81176), 595.97 MiB | 15.54 MiB/s, done.\n","Resolving deltas: 100% (57886/57886), done.\n"]}]},{"cell_type":"code","source":["pwd"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"uN6GCME904Nn","executionInfo":{"status":"ok","timestamp":1675846250873,"user_tz":-330,"elapsed":572,"user":{"displayName":"Vishnu Karande","userId":"00058094659799713799"}},"outputId":"73820e2a-bbdf-4237-bb65-76c3a8621c98"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["cd /content/models/research"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j3odDdnR1Msw","executionInfo":{"status":"ok","timestamp":1675846251539,"user_tz":-330,"elapsed":4,"user":{"displayName":"Vishnu Karande","userId":"00058094659799713799"}},"outputId":"17228d61-cb6c-44e4-869a-ec9fe1889775"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/models/research\n"]}]},{"cell_type":"code","source":["pwd"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"jwcpkqJM3Cob","executionInfo":{"status":"ok","timestamp":1675846252934,"user_tz":-330,"elapsed":10,"user":{"displayName":"Vishnu Karande","userId":"00058094659799713799"}},"outputId":"e12a1fb1-c75a-4ebb-a5d9-071ac024a5d5"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/models/research'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["!protoc object_detection/protos/*.proto --python_out=."],"metadata":{"id":"5Gw_jbZG3EZy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!git clone https://github.com/cocodataset/cocoapi.git"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fliAXz3b3X6C","executionInfo":{"status":"ok","timestamp":1675846258719,"user_tz":-330,"elapsed":2289,"user":{"displayName":"Vishnu Karande","userId":"00058094659799713799"}},"outputId":"59525321-e59b-4357-d3c2-d186897cd6b8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'cocoapi'...\n","remote: Enumerating objects: 975, done.\u001b[K\n","remote: Total 975 (delta 0), reused 0 (delta 0), pack-reused 975\u001b[K\n","Receiving objects: 100% (975/975), 11.72 MiB | 9.98 MiB/s, done.\n","Resolving deltas: 100% (576/576), done.\n"]}]},{"cell_type":"code","source":["cd cocoapi/PythonAPI"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TM6bwr9X3qui","executionInfo":{"status":"ok","timestamp":1675846260645,"user_tz":-330,"elapsed":7,"user":{"displayName":"Vishnu Karande","userId":"00058094659799713799"}},"outputId":"921e95fa-4cd2-4e17-ec44-6ae79f7a9695"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/models/research/cocoapi/PythonAPI\n"]}]},{"cell_type":"code","source":["!make"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b171b8Ih3ti6","executionInfo":{"status":"ok","timestamp":1675846271725,"user_tz":-330,"elapsed":8204,"user":{"displayName":"Vishnu Karande","userId":"00058094659799713799"}},"outputId":"f6baf37c-c7db-4c9c-eeeb-2193f9cd2801"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["python setup.py build_ext --inplace\n","running build_ext\n","cythoning pycocotools/_mask.pyx to pycocotools/_mask.c\n","/usr/local/lib/python3.8/dist-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /content/models/research/cocoapi/PythonAPI/pycocotools/_mask.pyx\n","  tree = Parsing.p_module(s, pxd, full_module_name)\n","building 'pycocotools._mask' extension\n","creating build\n","creating build/common\n","creating build/temp.linux-x86_64-3.8\n","creating build/temp.linux-x86_64-3.8/pycocotools\n","x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.8/dist-packages/numpy/core/include -I../common -I/usr/include/python3.8 -c ../common/maskApi.c -o build/temp.linux-x86_64-3.8/../common/maskApi.o -Wno-cpp -Wno-unused-function -std=c99\n","\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleDecode\u001b[m\u001b[K’:\n","\u001b[01m\u001b[K../common/maskApi.c:46:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n","   46 |       \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K( k=0; k<R[i].cnts[j]; k++ ) *(M++)=v; v=!v; }}\n","      |       \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K../common/maskApi.c:46:49:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’\n","   46 |       for( k=0; k<R[i].cnts[j]; k++ ) *(M++)=v; \u001b[01;36m\u001b[Kv\u001b[m\u001b[K=!v; }}\n","      |                                                 \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleFrPoly\u001b[m\u001b[K’:\n","\u001b[01m\u001b[K../common/maskApi.c:166:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n","  166 |   \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K(j=0; j<k; j++) x[j]=(int)(scale*xy[j*2+0]+.5); x[k]=x[0];\n","      |   \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K../common/maskApi.c:166:54:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’\n","  166 |   for(j=0; j<k; j++) x[j]=(int)(scale*xy[j*2+0]+.5); \u001b[01;36m\u001b[Kx\u001b[m\u001b[K[k]=x[0];\n","      |                                                      \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[K../common/maskApi.c:167:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n","  167 |   \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K(j=0; j<k; j++) y[j]=(int)(scale*xy[j*2+1]+.5); y[k]=y[0];\n","      |   \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K../common/maskApi.c:167:54:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’\n","  167 |   for(j=0; j<k; j++) y[j]=(int)(scale*xy[j*2+1]+.5); \u001b[01;36m\u001b[Ky\u001b[m\u001b[K[k]=y[0];\n","      |                                                      \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleToString\u001b[m\u001b[K’:\n","\u001b[01m\u001b[K../common/maskApi.c:212:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n","  212 |       \u001b[01;35m\u001b[Kif\u001b[m\u001b[K(more) c |= 0x20; c+=48; s[p++]=c;\n","      |       \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n","\u001b[01m\u001b[K../common/maskApi.c:212:27:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’\n","  212 |       if(more) c |= 0x20; \u001b[01;36m\u001b[Kc\u001b[m\u001b[K+=48; s[p++]=c;\n","      |                           \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n","\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleFrString\u001b[m\u001b[K’:\n","\u001b[01m\u001b[K../common/maskApi.c:220:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kwhile\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n","  220 |   \u001b[01;35m\u001b[Kwhile\u001b[m\u001b[K( s[m] ) m++; cnts=malloc(sizeof(uint)*m); m=0;\n","      |   \u001b[01;35m\u001b[K^~~~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K../common/maskApi.c:220:22:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kwhile\u001b[m\u001b[K’\n","  220 |   while( s[m] ) m++; \u001b[01;36m\u001b[Kcnts\u001b[m\u001b[K=malloc(sizeof(uint)*m); m=0;\n","      |                      \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n","\u001b[01m\u001b[K../common/maskApi.c:228:5:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n","  228 |     \u001b[01;35m\u001b[Kif\u001b[m\u001b[K(m>2) x+=(long) cnts[m-2]; cnts[m++]=(uint) x;\n","      |     \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n","\u001b[01m\u001b[K../common/maskApi.c:228:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’\n","  228 |     if(m>2) x+=(long) cnts[m-2]; \u001b[01;36m\u001b[Kcnts\u001b[m\u001b[K[m++]=(uint) x;\n","      |                                  \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n","x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.8/dist-packages/numpy/core/include -I../common -I/usr/include/python3.8 -c pycocotools/_mask.c -o build/temp.linux-x86_64-3.8/pycocotools/_mask.o -Wno-cpp -Wno-unused-function -std=c99\n","creating build/lib.linux-x86_64-3.8\n","creating build/lib.linux-x86_64-3.8/pycocotools\n","x86_64-linux-gnu-gcc -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -Wl,-Bsymbolic-functions -Wl,-z,relro -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.8/../common/maskApi.o build/temp.linux-x86_64-3.8/pycocotools/_mask.o -o build/lib.linux-x86_64-3.8/pycocotools/_mask.cpython-38-x86_64-linux-gnu.so\n","copying build/lib.linux-x86_64-3.8/pycocotools/_mask.cpython-38-x86_64-linux-gnu.so -> pycocotools\n","rm -rf build\n"]}]},{"cell_type":"code","source":["cp -r pycocotools /content/models/research"],"metadata":{"id":"19zvNWPz3vnJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[" cd .."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m6x9Snd93646","executionInfo":{"status":"ok","timestamp":1675846294417,"user_tz":-330,"elapsed":1,"user":{"displayName":"Vishnu Karande","userId":"00058094659799713799"}},"outputId":"8fdad6aa-8ac1-477b-c4ca-1c52b2a68ac4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/models/research/cocoapi\n"]}]},{"cell_type":"code","source":["cd .."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_t6iQRTj4W-C","executionInfo":{"status":"ok","timestamp":1675846298608,"user_tz":-330,"elapsed":570,"user":{"displayName":"Vishnu Karande","userId":"00058094659799713799"}},"outputId":"d5a21eb6-b68f-4fda-a4aa-ae2f42b3b090"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/models/research\n"]}]},{"cell_type":"code","source":["cp object_detection/packages/tf2/setup.py ."],"metadata":{"id":"JEPKibBM4czY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!python -m pip install ."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-G-XvfX_4jlp","executionInfo":{"status":"ok","timestamp":1675846391525,"user_tz":-330,"elapsed":90476,"user":{"displayName":"Vishnu Karande","userId":"00058094659799713799"}},"outputId":"d973c61c-1640-4523-d0a0-e059b1fc40ad"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Processing /content/models/research\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting avro-python3\n","  Downloading avro-python3-1.10.2.tar.gz (38 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting apache-beam\n","  Downloading apache_beam-2.44.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m65.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (7.1.2)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (4.9.2)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (3.2.2)\n","Requirement already satisfied: Cython in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (0.29.33)\n","Requirement already satisfied: contextlib2 in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (0.5.5)\n","Collecting tf-slim\n","  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m352.1/352.1 KB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (1.15.0)\n","Requirement already satisfied: pycocotools in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (2.0.6)\n","Collecting lvis\n","  Downloading lvis-0.5.3-py3-none-any.whl (14 kB)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (1.7.3)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (1.3.5)\n","Collecting tf-models-official>=2.5.1\n","  Downloading tf_models_official-2.11.3-py2.py3-none-any.whl (2.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m89.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tensorflow_io\n","  Downloading tensorflow_io-0.30.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (26.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.9/26.9 MB\u001b[0m \u001b[31m61.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: keras in /usr/local/lib/python3.8/dist-packages (from object-detection==0.1) (2.9.0)\n","Collecting pyparsing==2.4.7\n","  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.8/67.8 KB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting sacrebleu<=2.2.0\n","  Downloading sacrebleu-2.2.0-py3-none-any.whl (116 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.6/116.6 KB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting colorama\n","  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n","Collecting portalocker\n","  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (1.21.6)\n","Requirement already satisfied: regex in /usr/local/lib/python3.8/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (2022.6.2)\n","Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.8/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (0.8.10)\n","Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.5.12)\n","Collecting seqeval\n","  Downloading seqeval-1.2.2.tar.gz (43 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 KB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.8.2)\n","Collecting tensorflow-text~=2.11.0\n","  Downloading tensorflow_text-2.11.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m89.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.12.0)\n","Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.7.0.68)\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.97-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m81.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: gin-config in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.5.0)\n","Requirement already satisfied: oauth2client in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.1.3)\n","Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.70.0)\n","Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.8/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (5.4.8)\n","Collecting pyyaml<6.0,>=5.1\n","  Downloading PyYAML-5.4.1-cp38-cp38-manylinux1_x86_64.whl (662 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m662.4/662.4 KB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tensorflow-model-optimization>=0.4.1\n","  Downloading tensorflow_model_optimization-0.7.3-py2.py3-none-any.whl (238 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m238.9/238.9 KB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tensorflow-addons\n","  Downloading tensorflow_addons-0.19.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m70.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting immutabledict\n","  Downloading immutabledict-2.2.3-py3-none-any.whl (4.0 kB)\n","Collecting tensorflow~=2.11.0\n","  Downloading tensorflow-2.11.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (588.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m588.3/588.3 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting py-cpuinfo>=3.3.0\n","  Downloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->object-detection==0.1) (2022.7.1)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->object-detection==0.1) (2.8.2)\n","Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.8/dist-packages (from tf-slim->object-detection==0.1) (1.4.0)\n","Requirement already satisfied: httplib2<0.21.0,>=0.8 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (0.17.4)\n","Requirement already satisfied: proto-plus<2,>=1.7.1 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (1.22.2)\n","Requirement already satisfied: protobuf<4,>3.12.2 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (3.19.6)\n","Collecting hdfs<3.0.0,>=2.1.0\n","  Downloading hdfs-2.7.0-py3-none-any.whl (34 kB)\n","Collecting zstandard<1,>=0.18.0\n","  Downloading zstandard-0.19.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m90.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyarrow<10.0.0,>=0.15.1 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (9.0.0)\n","Collecting fasteners<1.0,>=0.3\n","  Downloading fasteners-0.18-py3-none-any.whl (18 kB)\n","Collecting pymongo<4.0.0,>=3.8.0\n","  Downloading pymongo-3.13.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (526 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m526.2/526.2 KB\u001b[0m \u001b[31m52.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: grpcio!=1.48.0,<2,>=1.33.1 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (1.51.1)\n","Collecting fastavro<2,>=0.23.6\n","  Downloading fastavro-1.7.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m100.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (1.7)\n","Requirement already satisfied: requests<3.0.0,>=2.24.0 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (2.25.1)\n","Collecting orjson<4.0\n","  Downloading orjson-3.8.5-cp38-cp38-manylinux_2_28_x86_64.whl (140 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 KB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting objsize<0.7.0,>=0.6.1\n","  Downloading objsize-0.6.1-py3-none-any.whl (9.3 kB)\n","Requirement already satisfied: typing-extensions>=3.7.0 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (4.4.0)\n","Requirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (1.3.0)\n","Collecting dill<0.3.2,>=0.3.1.1\n","  Downloading dill-0.3.1.1.tar.gz (151 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.0/152.0 KB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: cloudpickle~=2.2.0 in /usr/local/lib/python3.8/dist-packages (from apache-beam->object-detection==0.1) (2.2.1)\n","Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from lvis->object-detection==0.1) (0.11.0)\n","Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.8/dist-packages (from lvis->object-detection==0.1) (4.6.0.66)\n","Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from lvis->object-detection==0.1) (1.4.4)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem==0.30.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow_io->object-detection==0.1) (0.30.0)\n","Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /usr/local/lib/python3.8/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.11.0)\n","Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.8/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.1.1)\n","Requirement already satisfied: google-auth<3.0.0dev,>=1.19.0 in /usr/local/lib/python3.8/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.16.0)\n","Requirement already satisfied: google-auth-httplib2>=0.1.0 in /usr/local/lib/python3.8/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.1.0)\n","Collecting docopt\n","  Downloading docopt-0.6.2.tar.gz (25 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: certifi in /usr/local/lib/python3.8/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2022.12.7)\n","Requirement already satisfied: urllib3 in /usr/local/lib/python3.8/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.24.3)\n","Requirement already satisfied: python-slugify in /usr/local/lib/python3.8/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (8.0.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (4.64.1)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (4.0.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (2.10)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (1.6.3)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (0.2.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (57.4.0)\n","Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (1.14.1)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (15.0.6.1)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (2.2.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n","Collecting tensorflow-estimator<2.12,>=2.11.0\n","  Downloading tensorflow_estimator-2.11.0-py2.py3-none-any.whl (439 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m439.2/439.2 KB\u001b[0m \u001b[31m38.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tensorboard<2.12,>=2.11\n","  Downloading tensorboard-2.11.2-py3-none-any.whl (6.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m77.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (23.0)\n","Collecting keras\n","  Downloading keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m64.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting flatbuffers>=2.0\n","  Downloading flatbuffers-23.1.21-py2.py3-none-any.whl (26 kB)\n","Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official>=2.5.1->object-detection==0.1) (0.1.8)\n","Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.8/dist-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (0.4.8)\n","Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (4.9)\n","Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.8/dist-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (0.2.8)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.8/dist-packages (from seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.0.2)\n","Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.8/dist-packages (from tensorflow-addons->tf-models-official>=2.5.1->object-detection==0.1) (2.7.1)\n","Requirement already satisfied: etils[enp,epath]>=0.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.0.0)\n","Requirement already satisfied: importlib-resources in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (5.10.2)\n","Requirement already satisfied: promise in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (2.3)\n","Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (7.1.2)\n","Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.12.0)\n","Requirement already satisfied: toml in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (0.10.2)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (0.38.4)\n","Requirement already satisfied: zipp in /usr/local/lib/python3.8/dist-packages (from etils[enp,epath]>=0.9.0->tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (3.12.0)\n","Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.8/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.58.0)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3.0.0dev,>=1.19.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (5.3.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.2.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (3.4.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.6)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (1.0.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (1.8.1)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (0.6.1)\n","Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.8/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.3)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (6.0.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tf-models-official>=2.5.1->object-detection==0.1) (3.2.2)\n","Building wheels for collected packages: object-detection, avro-python3, dill, seqeval, docopt\n","  Building wheel for object-detection (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for object-detection: filename=object_detection-0.1-py3-none-any.whl size=1696777 sha256=5a77a1f5b5de534a9863fa56228f3a66597908e52779476000359dfafbb848c6\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-bo535sxw/wheels/7d/96/c1/072a751379735e8dfdada1def1c62a89afb3cc45654fd6fd28\n","  Building wheel for avro-python3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for avro-python3: filename=avro_python3-1.10.2-py3-none-any.whl size=44009 sha256=d61098b6a3203c7d30a6335a92530d9ce3c62ac50bba6c29473fef40813a7a14\n","  Stored in directory: /root/.cache/pip/wheels/bb/73/e9/d273421f5723c4bf544dcf9eb097bda94421ef8d3252699f0a\n","  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78544 sha256=87cd4cb93bf19b15993f2687b6a3923c126d13376559d18392875aa0dc19732e\n","  Stored in directory: /root/.cache/pip/wheels/07/35/78/e9004fa30578734db7f10e7a211605f3f0778d2bdde38a239d\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16179 sha256=05c8a61e3a14edcab2bfa6d967b01b68a31c4796c5967c6cf1f141291b8342db\n","  Stored in directory: /root/.cache/pip/wheels/ad/5c/ba/05fa33fa5855777b7d686e843ec07452f22a66a138e290e732\n","  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13723 sha256=5a93d62335fb167dfc6db6e4cdca3b1a0797d315fd15dc04b09cb9985980f116\n","  Stored in directory: /root/.cache/pip/wheels/56/ea/58/ead137b087d9e326852a851351d1debf4ada529b6ac0ec4e8c\n","Successfully built object-detection avro-python3 dill seqeval docopt\n","Installing collected packages: sentencepiece, py-cpuinfo, flatbuffers, docopt, zstandard, tf-slim, tensorflow-model-optimization, tensorflow_io, tensorflow-estimator, tensorflow-addons, pyyaml, pyparsing, pymongo, portalocker, orjson, objsize, keras, immutabledict, fasteners, fastavro, dill, colorama, avro-python3, sacrebleu, hdfs, seqeval, lvis, apache-beam, tensorboard, tensorflow, tensorflow-text, tf-models-official, object-detection\n","  Attempting uninstall: flatbuffers\n","    Found existing installation: flatbuffers 1.12\n","    Uninstalling flatbuffers-1.12:\n","      Successfully uninstalled flatbuffers-1.12\n","  Attempting uninstall: tensorflow-estimator\n","    Found existing installation: tensorflow-estimator 2.9.0\n","    Uninstalling tensorflow-estimator-2.9.0:\n","      Successfully uninstalled tensorflow-estimator-2.9.0\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 6.0\n","    Uninstalling PyYAML-6.0:\n","      Successfully uninstalled PyYAML-6.0\n","  Attempting uninstall: pyparsing\n","    Found existing installation: pyparsing 3.0.9\n","    Uninstalling pyparsing-3.0.9:\n","      Successfully uninstalled pyparsing-3.0.9\n","  Attempting uninstall: pymongo\n","    Found existing installation: pymongo 4.3.3\n","    Uninstalling pymongo-4.3.3:\n","      Successfully uninstalled pymongo-4.3.3\n","  Attempting uninstall: keras\n","    Found existing installation: keras 2.9.0\n","    Uninstalling keras-2.9.0:\n","      Successfully uninstalled keras-2.9.0\n","  Attempting uninstall: dill\n","    Found existing installation: dill 0.3.6\n","    Uninstalling dill-0.3.6:\n","      Successfully uninstalled dill-0.3.6\n","  Attempting uninstall: tensorboard\n","    Found existing installation: tensorboard 2.9.1\n","    Uninstalling tensorboard-2.9.1:\n","      Successfully uninstalled tensorboard-2.9.1\n","  Attempting uninstall: tensorflow\n","    Found existing installation: tensorflow 2.9.2\n","    Uninstalling tensorflow-2.9.2:\n","      Successfully uninstalled tensorflow-2.9.2\n","Successfully installed apache-beam-2.44.0 avro-python3-1.10.2 colorama-0.4.6 dill-0.3.1.1 docopt-0.6.2 fastavro-1.7.1 fasteners-0.18 flatbuffers-23.1.21 hdfs-2.7.0 immutabledict-2.2.3 keras-2.11.0 lvis-0.5.3 object-detection-0.1 objsize-0.6.1 orjson-3.8.5 portalocker-2.7.0 py-cpuinfo-9.0.0 pymongo-3.13.0 pyparsing-2.4.7 pyyaml-5.4.1 sacrebleu-2.2.0 sentencepiece-0.1.97 seqeval-1.2.2 tensorboard-2.11.2 tensorflow-2.11.0 tensorflow-addons-0.19.0 tensorflow-estimator-2.11.0 tensorflow-model-optimization-0.7.3 tensorflow-text-2.11.0 tensorflow_io-0.30.0 tf-models-official-2.11.3 tf-slim-1.1.0 zstandard-0.19.0\n"]}]},{"cell_type":"code","source":["# From within TensorFlow/models/research/\n","!python object_detection/builders/model_builder_tf2_test.py"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r53mFJoc4p8p","executionInfo":{"status":"ok","timestamp":1675846440577,"user_tz":-330,"elapsed":49055,"user":{"displayName":"Vishnu Karande","userId":"00058094659799713799"}},"outputId":"e6032b62-6e9c-461a-c007-cf15d888bab2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2023-02-08 08:53:12.379647: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n","2023-02-08 08:53:12.379844: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n","2023-02-08 08:53:12.379872: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n","Running tests under Python 3.8.10: /usr/bin/python3\n","[ RUN      ] ModelBuilderTF2Test.test_create_center_net_deepmac\n","2023-02-08 08:53:18.195702: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","W0208 08:53:18.472748 140581640709952 model_builder.py:1112] Building experimental DeepMAC meta-arch. Some features may be omitted.\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 1.45s\n","I0208 08:53:18.748742 140581640709952 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 1.45s\n","[       OK ] ModelBuilderTF2Test.test_create_center_net_deepmac\n","[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.85s\n","I0208 08:53:19.601759 140581640709952 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.85s\n","[       OK ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n","[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.51s\n","I0208 08:53:20.108851 140581640709952 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.51s\n","[       OK ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n","[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.56s\n","I0208 08:53:20.665754 140581640709952 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.56s\n","[       OK ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n","[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 2.52s\n","I0208 08:53:23.187605 140581640709952 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 2.52s\n","[       OK ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n","[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n","I0208 08:53:23.195599 140581640709952 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_create_experimental_model\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.03s\n","I0208 08:53:23.221357 140581640709952 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.03s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.02s\n","I0208 08:53:23.238261 140581640709952 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.02s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.02s\n","I0208 08:53:23.256274 140581640709952 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.02s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.27s\n","I0208 08:53:23.525081 140581640709952 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.27s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.1s\n","I0208 08:53:23.622072 140581640709952 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.1s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.1s\n","I0208 08:53:23.724508 140581640709952 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.1s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.1s\n","I0208 08:53:23.826078 140581640709952 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.1s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n","[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.1s\n","I0208 08:53:23.923829 140581640709952 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.1s\n","[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n","[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.03s\n","I0208 08:53:23.955167 140581640709952 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.03s\n","[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n","[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n","I0208 08:53:24.144036 140581640709952 ssd_efficientnet_bifpn_feature_extractor.py:150] EfficientDet EfficientNet backbone version: efficientnet-b0\n","I0208 08:53:24.144233 140581640709952 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 64\n","I0208 08:53:24.144304 140581640709952 ssd_efficientnet_bifpn_feature_extractor.py:153] EfficientDet BiFPN num iterations: 3\n","I0208 08:53:24.146588 140581640709952 efficientnet_model.py:143] round_filter input=32 output=32\n","I0208 08:53:24.175029 140581640709952 efficientnet_model.py:143] round_filter input=32 output=32\n","I0208 08:53:24.175199 140581640709952 efficientnet_model.py:143] round_filter input=16 output=16\n","I0208 08:53:24.248793 140581640709952 efficientnet_model.py:143] round_filter input=16 output=16\n","I0208 08:53:24.248969 140581640709952 efficientnet_model.py:143] round_filter input=24 output=24\n","I0208 08:53:24.448262 140581640709952 efficientnet_model.py:143] round_filter input=24 output=24\n","I0208 08:53:24.448424 140581640709952 efficientnet_model.py:143] round_filter input=40 output=40\n","I0208 08:53:24.640491 140581640709952 efficientnet_model.py:143] round_filter input=40 output=40\n","I0208 08:53:24.640688 140581640709952 efficientnet_model.py:143] round_filter input=80 output=80\n","I0208 08:53:24.921614 140581640709952 efficientnet_model.py:143] round_filter input=80 output=80\n","I0208 08:53:24.921829 140581640709952 efficientnet_model.py:143] round_filter input=112 output=112\n","I0208 08:53:25.207732 140581640709952 efficientnet_model.py:143] round_filter input=112 output=112\n","I0208 08:53:25.207901 140581640709952 efficientnet_model.py:143] round_filter input=192 output=192\n","I0208 08:53:25.581155 140581640709952 efficientnet_model.py:143] round_filter input=192 output=192\n","I0208 08:53:25.581331 140581640709952 efficientnet_model.py:143] round_filter input=320 output=320\n","I0208 08:53:25.670656 140581640709952 efficientnet_model.py:143] round_filter input=1280 output=1280\n","I0208 08:53:25.712904 140581640709952 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0208 08:53:25.773222 140581640709952 ssd_efficientnet_bifpn_feature_extractor.py:150] EfficientDet EfficientNet backbone version: efficientnet-b1\n","I0208 08:53:25.773400 140581640709952 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 88\n","I0208 08:53:25.773484 140581640709952 ssd_efficientnet_bifpn_feature_extractor.py:153] EfficientDet BiFPN num iterations: 4\n","I0208 08:53:25.775318 140581640709952 efficientnet_model.py:143] round_filter input=32 output=32\n","I0208 08:53:25.794929 140581640709952 efficientnet_model.py:143] round_filter input=32 output=32\n","I0208 08:53:25.795077 140581640709952 efficientnet_model.py:143] round_filter input=16 output=16\n","I0208 08:53:25.960999 140581640709952 efficientnet_model.py:143] round_filter input=16 output=16\n","I0208 08:53:25.961208 140581640709952 efficientnet_model.py:143] round_filter input=24 output=24\n","I0208 08:53:26.216617 140581640709952 efficientnet_model.py:143] round_filter input=24 output=24\n","I0208 08:53:26.216785 140581640709952 efficientnet_model.py:143] round_filter input=40 output=40\n","I0208 08:53:26.474899 140581640709952 efficientnet_model.py:143] round_filter input=40 output=40\n","I0208 08:53:26.475102 140581640709952 efficientnet_model.py:143] round_filter input=80 output=80\n","I0208 08:53:26.829049 140581640709952 efficientnet_model.py:143] round_filter input=80 output=80\n","I0208 08:53:26.829233 140581640709952 efficientnet_model.py:143] round_filter input=112 output=112\n","I0208 08:53:27.203254 140581640709952 efficientnet_model.py:143] round_filter input=112 output=112\n","I0208 08:53:27.203484 140581640709952 efficientnet_model.py:143] round_filter input=192 output=192\n","I0208 08:53:27.826782 140581640709952 efficientnet_model.py:143] round_filter input=192 output=192\n","I0208 08:53:27.826992 140581640709952 efficientnet_model.py:143] round_filter input=320 output=320\n","I0208 08:53:28.077102 140581640709952 efficientnet_model.py:143] round_filter input=1280 output=1280\n","I0208 08:53:28.125141 140581640709952 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0208 08:53:28.219573 140581640709952 ssd_efficientnet_bifpn_feature_extractor.py:150] EfficientDet EfficientNet backbone version: efficientnet-b2\n","I0208 08:53:28.219781 140581640709952 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 112\n","I0208 08:53:28.219869 140581640709952 ssd_efficientnet_bifpn_feature_extractor.py:153] EfficientDet BiFPN num iterations: 5\n","I0208 08:53:28.222457 140581640709952 efficientnet_model.py:143] round_filter input=32 output=32\n","I0208 08:53:28.249415 140581640709952 efficientnet_model.py:143] round_filter input=32 output=32\n","I0208 08:53:28.249604 140581640709952 efficientnet_model.py:143] round_filter input=16 output=16\n","I0208 08:53:28.442160 140581640709952 efficientnet_model.py:143] round_filter input=16 output=16\n","I0208 08:53:28.442357 140581640709952 efficientnet_model.py:143] round_filter input=24 output=24\n","I0208 08:53:28.802281 140581640709952 efficientnet_model.py:143] round_filter input=24 output=24\n","I0208 08:53:28.802474 140581640709952 efficientnet_model.py:143] round_filter input=40 output=48\n","I0208 08:53:29.439202 140581640709952 efficientnet_model.py:143] round_filter input=40 output=48\n","I0208 08:53:29.439410 140581640709952 efficientnet_model.py:143] round_filter input=80 output=88\n","I0208 08:53:30.032252 140581640709952 efficientnet_model.py:143] round_filter input=80 output=88\n","I0208 08:53:30.032467 140581640709952 efficientnet_model.py:143] round_filter input=112 output=120\n","I0208 08:53:30.603451 140581640709952 efficientnet_model.py:143] round_filter input=112 output=120\n","I0208 08:53:30.603677 140581640709952 efficientnet_model.py:143] round_filter input=192 output=208\n","I0208 08:53:31.307572 140581640709952 efficientnet_model.py:143] round_filter input=192 output=208\n","I0208 08:53:31.307783 140581640709952 efficientnet_model.py:143] round_filter input=320 output=352\n","I0208 08:53:31.593930 140581640709952 efficientnet_model.py:143] round_filter input=1280 output=1408\n","I0208 08:53:31.661615 140581640709952 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0208 08:53:31.757944 140581640709952 ssd_efficientnet_bifpn_feature_extractor.py:150] EfficientDet EfficientNet backbone version: efficientnet-b3\n","I0208 08:53:31.758177 140581640709952 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 160\n","I0208 08:53:31.758271 140581640709952 ssd_efficientnet_bifpn_feature_extractor.py:153] EfficientDet BiFPN num iterations: 6\n","I0208 08:53:31.760795 140581640709952 efficientnet_model.py:143] round_filter input=32 output=40\n","I0208 08:53:31.793950 140581640709952 efficientnet_model.py:143] round_filter input=32 output=40\n","I0208 08:53:31.794177 140581640709952 efficientnet_model.py:143] round_filter input=16 output=24\n","I0208 08:53:32.033001 140581640709952 efficientnet_model.py:143] round_filter input=16 output=24\n","I0208 08:53:32.033243 140581640709952 efficientnet_model.py:143] round_filter input=24 output=32\n","I0208 08:53:32.453204 140581640709952 efficientnet_model.py:143] round_filter input=24 output=32\n","I0208 08:53:32.453407 140581640709952 efficientnet_model.py:143] round_filter input=40 output=48\n","I0208 08:53:32.860774 140581640709952 efficientnet_model.py:143] round_filter input=40 output=48\n","I0208 08:53:32.860990 140581640709952 efficientnet_model.py:143] round_filter input=80 output=96\n","I0208 08:53:33.569135 140581640709952 efficientnet_model.py:143] round_filter input=80 output=96\n","I0208 08:53:33.569350 140581640709952 efficientnet_model.py:143] round_filter input=112 output=136\n","I0208 08:53:34.266796 140581640709952 efficientnet_model.py:143] round_filter input=112 output=136\n","I0208 08:53:34.267009 140581640709952 efficientnet_model.py:143] round_filter input=192 output=232\n","I0208 08:53:35.100394 140581640709952 efficientnet_model.py:143] round_filter input=192 output=232\n","I0208 08:53:35.100605 140581640709952 efficientnet_model.py:143] round_filter input=320 output=384\n","I0208 08:53:35.390059 140581640709952 efficientnet_model.py:143] round_filter input=1280 output=1536\n","I0208 08:53:35.451967 140581640709952 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0208 08:53:35.550597 140581640709952 ssd_efficientnet_bifpn_feature_extractor.py:150] EfficientDet EfficientNet backbone version: efficientnet-b4\n","I0208 08:53:35.550792 140581640709952 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 224\n","I0208 08:53:35.550876 140581640709952 ssd_efficientnet_bifpn_feature_extractor.py:153] EfficientDet BiFPN num iterations: 7\n","I0208 08:53:35.553608 140581640709952 efficientnet_model.py:143] round_filter input=32 output=48\n","I0208 08:53:35.583871 140581640709952 efficientnet_model.py:143] round_filter input=32 output=48\n","I0208 08:53:35.584056 140581640709952 efficientnet_model.py:143] round_filter input=16 output=24\n","I0208 08:53:35.806203 140581640709952 efficientnet_model.py:143] round_filter input=16 output=24\n","I0208 08:53:35.806411 140581640709952 efficientnet_model.py:143] round_filter input=24 output=32\n","I0208 08:53:36.345621 140581640709952 efficientnet_model.py:143] round_filter input=24 output=32\n","I0208 08:53:36.345830 140581640709952 efficientnet_model.py:143] round_filter input=40 output=56\n","I0208 08:53:36.830306 140581640709952 efficientnet_model.py:143] round_filter input=40 output=56\n","I0208 08:53:36.830495 140581640709952 efficientnet_model.py:143] round_filter input=80 output=112\n","I0208 08:53:37.394857 140581640709952 efficientnet_model.py:143] round_filter input=80 output=112\n","I0208 08:53:37.395029 140581640709952 efficientnet_model.py:143] round_filter input=112 output=160\n","I0208 08:53:37.955613 140581640709952 efficientnet_model.py:143] round_filter input=112 output=160\n","I0208 08:53:37.955782 140581640709952 efficientnet_model.py:143] round_filter input=192 output=272\n","I0208 08:53:38.963083 140581640709952 efficientnet_model.py:143] round_filter input=192 output=272\n","I0208 08:53:38.963275 140581640709952 efficientnet_model.py:143] round_filter input=320 output=448\n","I0208 08:53:39.166262 140581640709952 efficientnet_model.py:143] round_filter input=1280 output=1792\n","I0208 08:53:39.206392 140581640709952 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0208 08:53:39.279026 140581640709952 ssd_efficientnet_bifpn_feature_extractor.py:150] EfficientDet EfficientNet backbone version: efficientnet-b5\n","I0208 08:53:39.279208 140581640709952 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 288\n","I0208 08:53:39.279283 140581640709952 ssd_efficientnet_bifpn_feature_extractor.py:153] EfficientDet BiFPN num iterations: 7\n","I0208 08:53:39.280969 140581640709952 efficientnet_model.py:143] round_filter input=32 output=48\n","I0208 08:53:39.299184 140581640709952 efficientnet_model.py:143] round_filter input=32 output=48\n","I0208 08:53:39.299329 140581640709952 efficientnet_model.py:143] round_filter input=16 output=24\n","I0208 08:53:39.513600 140581640709952 efficientnet_model.py:143] round_filter input=16 output=24\n","I0208 08:53:39.513774 140581640709952 efficientnet_model.py:143] round_filter input=24 output=40\n","I0208 08:53:39.964105 140581640709952 efficientnet_model.py:143] round_filter input=24 output=40\n","I0208 08:53:39.964281 140581640709952 efficientnet_model.py:143] round_filter input=40 output=64\n","I0208 08:53:40.452606 140581640709952 efficientnet_model.py:143] round_filter input=40 output=64\n","I0208 08:53:40.452785 140581640709952 efficientnet_model.py:143] round_filter input=80 output=128\n","I0208 08:53:41.100731 140581640709952 efficientnet_model.py:143] round_filter input=80 output=128\n","I0208 08:53:41.100911 140581640709952 efficientnet_model.py:143] round_filter input=112 output=176\n","I0208 08:53:41.733668 140581640709952 efficientnet_model.py:143] round_filter input=112 output=176\n","I0208 08:53:41.733856 140581640709952 efficientnet_model.py:143] round_filter input=192 output=304\n","I0208 08:53:42.546575 140581640709952 efficientnet_model.py:143] round_filter input=192 output=304\n","I0208 08:53:42.546740 140581640709952 efficientnet_model.py:143] round_filter input=320 output=512\n","I0208 08:53:42.822372 140581640709952 efficientnet_model.py:143] round_filter input=1280 output=2048\n","I0208 08:53:42.864606 140581640709952 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0208 08:53:42.941437 140581640709952 ssd_efficientnet_bifpn_feature_extractor.py:150] EfficientDet EfficientNet backbone version: efficientnet-b6\n","I0208 08:53:42.941606 140581640709952 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 384\n","I0208 08:53:42.941680 140581640709952 ssd_efficientnet_bifpn_feature_extractor.py:153] EfficientDet BiFPN num iterations: 8\n","I0208 08:53:42.943298 140581640709952 efficientnet_model.py:143] round_filter input=32 output=56\n","I0208 08:53:42.969877 140581640709952 efficientnet_model.py:143] round_filter input=32 output=56\n","I0208 08:53:42.970044 140581640709952 efficientnet_model.py:143] round_filter input=16 output=32\n","I0208 08:53:43.185995 140581640709952 efficientnet_model.py:143] round_filter input=16 output=32\n","I0208 08:53:43.186186 140581640709952 efficientnet_model.py:143] round_filter input=24 output=40\n","I0208 08:53:43.707379 140581640709952 efficientnet_model.py:143] round_filter input=24 output=40\n","I0208 08:53:43.707553 140581640709952 efficientnet_model.py:143] round_filter input=40 output=72\n","I0208 08:53:44.246693 140581640709952 efficientnet_model.py:143] round_filter input=40 output=72\n","I0208 08:53:44.246859 140581640709952 efficientnet_model.py:143] round_filter input=80 output=144\n","I0208 08:53:44.963914 140581640709952 efficientnet_model.py:143] round_filter input=80 output=144\n","I0208 08:53:44.964085 140581640709952 efficientnet_model.py:143] round_filter input=112 output=200\n","I0208 08:53:45.996925 140581640709952 efficientnet_model.py:143] round_filter input=112 output=200\n","I0208 08:53:45.997103 140581640709952 efficientnet_model.py:143] round_filter input=192 output=344\n","I0208 08:53:47.382583 140581640709952 efficientnet_model.py:143] round_filter input=192 output=344\n","I0208 08:53:47.382783 140581640709952 efficientnet_model.py:143] round_filter input=320 output=576\n","I0208 08:53:47.836698 140581640709952 efficientnet_model.py:143] round_filter input=1280 output=2304\n","I0208 08:53:47.890281 140581640709952 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0208 08:53:48.051872 140581640709952 ssd_efficientnet_bifpn_feature_extractor.py:150] EfficientDet EfficientNet backbone version: efficientnet-b7\n","I0208 08:53:48.052069 140581640709952 ssd_efficientnet_bifpn_feature_extractor.py:152] EfficientDet BiFPN num filters: 384\n","I0208 08:53:48.052153 140581640709952 ssd_efficientnet_bifpn_feature_extractor.py:153] EfficientDet BiFPN num iterations: 8\n","I0208 08:53:48.057701 140581640709952 efficientnet_model.py:143] round_filter input=32 output=64\n","I0208 08:53:48.097552 140581640709952 efficientnet_model.py:143] round_filter input=32 output=64\n","I0208 08:53:48.097743 140581640709952 efficientnet_model.py:143] round_filter input=16 output=32\n","I0208 08:53:48.600789 140581640709952 efficientnet_model.py:143] round_filter input=16 output=32\n","I0208 08:53:48.600988 140581640709952 efficientnet_model.py:143] round_filter input=24 output=48\n","I0208 08:53:49.562761 140581640709952 efficientnet_model.py:143] round_filter input=24 output=48\n","I0208 08:53:49.562964 140581640709952 efficientnet_model.py:143] round_filter input=40 output=80\n","I0208 08:53:50.587017 140581640709952 efficientnet_model.py:143] round_filter input=40 output=80\n","I0208 08:53:50.588830 140581640709952 efficientnet_model.py:143] round_filter input=80 output=160\n","I0208 08:53:52.305442 140581640709952 efficientnet_model.py:143] round_filter input=80 output=160\n","I0208 08:53:52.305648 140581640709952 efficientnet_model.py:143] round_filter input=112 output=224\n","I0208 08:53:54.036936 140581640709952 efficientnet_model.py:143] round_filter input=112 output=224\n","I0208 08:53:54.037171 140581640709952 efficientnet_model.py:143] round_filter input=192 output=384\n","I0208 08:53:56.295178 140581640709952 efficientnet_model.py:143] round_filter input=192 output=384\n","I0208 08:53:56.295383 140581640709952 efficientnet_model.py:143] round_filter input=320 output=640\n","I0208 08:53:57.027012 140581640709952 efficientnet_model.py:143] round_filter input=1280 output=2560\n","I0208 08:53:57.110046 140581640709952 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 33.85s\n","I0208 08:53:57.802525 140581640709952 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 33.85s\n","[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n","[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.01s\n","I0208 08:53:57.865204 140581640709952 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.01s\n","[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n","[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n","I0208 08:53:57.868682 140581640709952 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n","[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n","I0208 08:53:57.869516 140581640709952 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto\n","[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n","I0208 08:53:57.872348 140581640709952 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n","[ RUN      ] ModelBuilderTF2Test.test_session\n","[  SKIPPED ] ModelBuilderTF2Test.test_session\n","[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n","I0208 08:53:57.874865 140581640709952 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n","[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n","I0208 08:53:57.877145 140581640709952 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture\n","[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n","I0208 08:53:57.879892 140581640709952 test_util.py:2457] time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n","----------------------------------------------------------------------\n","Ran 24 tests in 40.580s\n","\n","OK (skipped=1)\n"]}]},{"cell_type":"code","source":["cd /content/traning_demo/pre-trained-models"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PAdeQ4BS5HyU","executionInfo":{"status":"ok","timestamp":1675847486659,"user_tz":-330,"elapsed":2,"user":{"displayName":"Vishnu Karande","userId":"00058094659799713799"}},"outputId":"c0ca54b5-aedd-4018-d3f5-deedecbcdce3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/traning_demo/pre-trained-models\n"]}]},{"cell_type":"code","source":["!wget http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_resnet101_v1_fpn_640x640_coco17_tpu-8.tar.gz"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4bUHaT_nS0YC","executionInfo":{"status":"ok","timestamp":1675847580889,"user_tz":-330,"elapsed":8309,"user":{"displayName":"Vishnu Karande","userId":"00058094659799713799"}},"outputId":"60306d1f-288d-40e7-f575-55b89849d20c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--2023-02-08 09:12:52--  http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_resnet101_v1_fpn_640x640_coco17_tpu-8.tar.gz\n","Resolving download.tensorflow.org (download.tensorflow.org)... 142.250.4.128, 2404:6800:4003:c03::80\n","Connecting to download.tensorflow.org (download.tensorflow.org)|142.250.4.128|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 386527459 (369M) [application/x-tar]\n","Saving to: ‘ssd_resnet101_v1_fpn_640x640_coco17_tpu-8.tar.gz’\n","\n","ssd_resnet101_v1_fp 100%[===================>] 368.62M  63.8MB/s    in 6.8s    \n","\n","2023-02-08 09:13:00 (54.6 MB/s) - ‘ssd_resnet101_v1_fpn_640x640_coco17_tpu-8.tar.gz’ saved [386527459/386527459]\n","\n"]}]},{"cell_type":"code","source":["!tar -xvf ssd_resnet101_v1_fpn_640x640_coco17_tpu-8.tar.gz"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Nc_GByYaTJWi","executionInfo":{"status":"ok","timestamp":1675847649894,"user_tz":-330,"elapsed":4765,"user":{"displayName":"Vishnu Karande","userId":"00058094659799713799"}},"outputId":"308c17c2-1e6b-4feb-e4e9-ac2d3755df24"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/\n","ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/checkpoint/\n","ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/checkpoint/ckpt-0.data-00000-of-00001\n","ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/checkpoint/checkpoint\n","ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/checkpoint/ckpt-0.index\n","ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/pipeline.config\n","ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/saved_model/\n","ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/saved_model/saved_model.pb\n","ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/saved_model/assets/\n","ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/saved_model/variables/\n","ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/saved_model/variables/variables.data-00000-of-00001\n","ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/saved_model/variables/variables.index\n"]}]},{"cell_type":"code","source":["pwd"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"bBArh9E0TbFk","executionInfo":{"status":"ok","timestamp":1675847684164,"user_tz":-330,"elapsed":7,"user":{"displayName":"Vishnu Karande","userId":"00058094659799713799"}},"outputId":"fa8acc8a-0b86-41d3-8b21-f38eeadbd66f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/traning_demo/pre-trained-models'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":[" cd /content/traning_demo"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w4_qw5YDTklp","executionInfo":{"status":"ok","timestamp":1675848505509,"user_tz":-330,"elapsed":5,"user":{"displayName":"Vishnu Karande","userId":"00058094659799713799"}},"outputId":"8aa5eec1-e183-46b7-ddcd-eeb2a6c69591"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/traning_demo\n"]}]},{"cell_type":"code","source":["# Create train data:\n","!python generate_tfrecord.py -x /content/traning_demo/images/train -l /content/traning_demo/annotations/label_map.pbtxt -o /content/traning_demo/annotations/train.record\n","\n","# Create test data:\n","!python generate_tfrecord.py -x /content/traning_demo/images/test -l /content/traning_demo/annotations/label_map.pbtxt -o /content/traning_demo/annotations/test.record"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l2TOom7nWkqx","executionInfo":{"status":"ok","timestamp":1675849025474,"user_tz":-330,"elapsed":9384,"user":{"displayName":"Vishnu Karande","userId":"00058094659799713799"}},"outputId":"352b459c-de08-411f-e736-8adad702fda4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Successfully created the TFRecord file: /content/traning_demo/annotations/train.record\n","Successfully created the TFRecord file: /content/traning_demo/annotations/test.record\n"]}]},{"cell_type":"code","source":["pwd"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"isnpzL4hXI9I","executionInfo":{"status":"ok","timestamp":1675850019287,"user_tz":-330,"elapsed":7,"user":{"displayName":"Vishnu Karande","userId":"00058094659799713799"}},"outputId":"83aef5a3-a239-492f-a350-477e91dd8233"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/traning_demo'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":28}]},{"cell_type":"code","source":["ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GFAy6WuXce3E","executionInfo":{"status":"ok","timestamp":1675850030537,"user_tz":-330,"elapsed":854,"user":{"displayName":"Vishnu Karande","userId":"00058094659799713799"}},"outputId":"641bc45c-d333-4bbd-81b9-d3741be9304a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[0m\u001b[01;34mannotations\u001b[0m/         export_tflite_graph_tf2.py  \u001b[01;34mmodels\u001b[0m/\n","Bike.csv             generate_tfrecord.py        \u001b[01;34mpre-trained-models\u001b[0m/\n","\u001b[01;34mexported-models\u001b[0m/     \u001b[01;34mimages\u001b[0m/\n","exporter_main_v2.py  model_main_tf2.py\n"]}]},{"cell_type":"code","source":["!python model_main_tf2.py --model_dir=/content/traning_demo/models/my_ssd_resnet101_v1_fpn --pipeline_config_path=/content/traning_demo/models/my_ssd_resnet101_v1_fpn/pipeline.config"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vVzLoFZ6chZD","executionInfo":{"status":"ok","timestamp":1675854319198,"user_tz":-330,"elapsed":2015282,"user":{"displayName":"Vishnu Karande","userId":"00058094659799713799"}},"outputId":"2c5fb138-3c53-4380-e3b7-146d9042f34f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2023-02-08 10:31:45.139090: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n","2023-02-08 10:31:45.139241: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n","2023-02-08 10:31:45.139269: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n","2023-02-08 10:31:49.077835: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n","I0208 10:31:49.101187 140571417827136 mirrored_strategy.py:374] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n","INFO:tensorflow:Maybe overwriting train_steps: None\n","I0208 10:31:49.104979 140571417827136 config_util.py:552] Maybe overwriting train_steps: None\n","INFO:tensorflow:Maybe overwriting use_bfloat16: False\n","I0208 10:31:49.105159 140571417827136 config_util.py:552] Maybe overwriting use_bfloat16: False\n","WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/object_detection/model_lib_v2.py:563: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","rename to distribute_datasets_from_function\n","W0208 10:31:49.131287 140571417827136 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/object_detection/model_lib_v2.py:563: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","rename to distribute_datasets_from_function\n","INFO:tensorflow:Reading unweighted datasets: ['/content/traning_demo/annotations/train.record']\n","I0208 10:31:49.138609 140571417827136 dataset_builder.py:162] Reading unweighted datasets: ['/content/traning_demo/annotations/train.record']\n","INFO:tensorflow:Reading record datasets for input file: ['/content/traning_demo/annotations/train.record']\n","I0208 10:31:49.138807 140571417827136 dataset_builder.py:79] Reading record datasets for input file: ['/content/traning_demo/annotations/train.record']\n","INFO:tensorflow:Number of filenames to read: 1\n","I0208 10:31:49.138893 140571417827136 dataset_builder.py:80] Number of filenames to read: 1\n","WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n","W0208 10:31:49.138959 140571417827136 dataset_builder.py:86] num_readers has been reduced to 1 to match input file shards.\n","WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n","W0208 10:31:49.145339 140571417827136 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n","WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.map()\n","W0208 10:31:49.162631 140571417827136 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.map()\n","WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n","Instructions for updating:\n","Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n","W0208 10:31:49.738165 140571417827136 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n","Instructions for updating:\n","Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n","WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n","W0208 10:31:55.103735 140571417827136 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n","WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n","W0208 10:31:58.777628 140571417827136 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n","WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","W0208 10:32:01.127701 140571417827136 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","/usr/local/lib/python3.8/dist-packages/keras/backend.py:451: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n","  warnings.warn(\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0208 10:32:48.962852 140571417827136 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0208 10:32:48.965793 140571417827136 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0208 10:32:48.966938 140571417827136 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0208 10:32:48.967940 140571417827136 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0208 10:32:48.971457 140571417827136 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0208 10:32:48.972450 140571417827136 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0208 10:32:48.973480 140571417827136 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0208 10:32:48.974466 140571417827136 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0208 10:32:48.978035 140571417827136 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","I0208 10:32:48.979025 140571417827136 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n","WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/deprecation.py:629: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use fn_output_signature instead\n","W0208 10:32:51.359301 140567132501760 deprecation.py:554] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/deprecation.py:629: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use fn_output_signature instead\n","INFO:tensorflow:Step 100 per-step time 2.531s\n","I0208 10:37:04.180101 140571417827136 model_lib_v2.py:705] Step 100 per-step time 2.531s\n","INFO:tensorflow:{'Loss/classification_loss': 0.1772069,\n"," 'Loss/localization_loss': 0.06689526,\n"," 'Loss/regularization_loss': 0.46141532,\n"," 'Loss/total_loss': 0.7055175,\n"," 'learning_rate': 0.0159997}\n","I0208 10:37:04.180526 140571417827136 model_lib_v2.py:708] {'Loss/classification_loss': 0.1772069,\n"," 'Loss/localization_loss': 0.06689526,\n"," 'Loss/regularization_loss': 0.46141532,\n"," 'Loss/total_loss': 0.7055175,\n"," 'learning_rate': 0.0159997}\n","INFO:tensorflow:Step 200 per-step time 1.830s\n","I0208 10:40:07.160287 140571417827136 model_lib_v2.py:705] Step 200 per-step time 1.830s\n","INFO:tensorflow:{'Loss/classification_loss': 0.48686025,\n"," 'Loss/localization_loss': 0.31188217,\n"," 'Loss/regularization_loss': 3.961095,\n"," 'Loss/total_loss': 4.7598376,\n"," 'learning_rate': 0.0186664}\n","I0208 10:40:07.160737 140571417827136 model_lib_v2.py:708] {'Loss/classification_loss': 0.48686025,\n"," 'Loss/localization_loss': 0.31188217,\n"," 'Loss/regularization_loss': 3.961095,\n"," 'Loss/total_loss': 4.7598376,\n"," 'learning_rate': 0.0186664}\n","INFO:tensorflow:Step 300 per-step time 1.829s\n","I0208 10:43:10.022018 140571417827136 model_lib_v2.py:705] Step 300 per-step time 1.829s\n","INFO:tensorflow:{'Loss/classification_loss': 0.28155616,\n"," 'Loss/localization_loss': 0.14752592,\n"," 'Loss/regularization_loss': 4.202997,\n"," 'Loss/total_loss': 4.632079,\n"," 'learning_rate': 0.0213331}\n","I0208 10:43:10.022492 140571417827136 model_lib_v2.py:708] {'Loss/classification_loss': 0.28155616,\n"," 'Loss/localization_loss': 0.14752592,\n"," 'Loss/regularization_loss': 4.202997,\n"," 'Loss/total_loss': 4.632079,\n"," 'learning_rate': 0.0213331}\n","INFO:tensorflow:Step 400 per-step time 1.831s\n","I0208 10:46:13.096929 140571417827136 model_lib_v2.py:705] Step 400 per-step time 1.831s\n","INFO:tensorflow:{'Loss/classification_loss': 0.1583773,\n"," 'Loss/localization_loss': 0.04579601,\n"," 'Loss/regularization_loss': 4.1294165,\n"," 'Loss/total_loss': 4.3335896,\n"," 'learning_rate': 0.023999799}\n","I0208 10:46:13.097385 140571417827136 model_lib_v2.py:708] {'Loss/classification_loss': 0.1583773,\n"," 'Loss/localization_loss': 0.04579601,\n"," 'Loss/regularization_loss': 4.1294165,\n"," 'Loss/total_loss': 4.3335896,\n"," 'learning_rate': 0.023999799}\n","INFO:tensorflow:Step 500 per-step time 1.833s\n","I0208 10:49:16.342328 140571417827136 model_lib_v2.py:705] Step 500 per-step time 1.833s\n","INFO:tensorflow:{'Loss/classification_loss': 0.13042521,\n"," 'Loss/localization_loss': 0.046035245,\n"," 'Loss/regularization_loss': 4.048313,\n"," 'Loss/total_loss': 4.2247734,\n"," 'learning_rate': 0.0266665}\n","I0208 10:49:16.342705 140571417827136 model_lib_v2.py:708] {'Loss/classification_loss': 0.13042521,\n"," 'Loss/localization_loss': 0.046035245,\n"," 'Loss/regularization_loss': 4.048313,\n"," 'Loss/total_loss': 4.2247734,\n"," 'learning_rate': 0.0266665}\n","INFO:tensorflow:Step 600 per-step time 1.831s\n","I0208 10:52:19.423386 140571417827136 model_lib_v2.py:705] Step 600 per-step time 1.831s\n","INFO:tensorflow:{'Loss/classification_loss': 0.12073212,\n"," 'Loss/localization_loss': 0.02395234,\n"," 'Loss/regularization_loss': 3.9602973,\n"," 'Loss/total_loss': 4.104982,\n"," 'learning_rate': 0.0293332}\n","I0208 10:52:19.423851 140571417827136 model_lib_v2.py:708] {'Loss/classification_loss': 0.12073212,\n"," 'Loss/localization_loss': 0.02395234,\n"," 'Loss/regularization_loss': 3.9602973,\n"," 'Loss/total_loss': 4.104982,\n"," 'learning_rate': 0.0293332}\n","INFO:tensorflow:Step 700 per-step time 1.835s\n","I0208 10:55:22.955264 140571417827136 model_lib_v2.py:705] Step 700 per-step time 1.835s\n","INFO:tensorflow:{'Loss/classification_loss': 0.093305096,\n"," 'Loss/localization_loss': 0.019611072,\n"," 'Loss/regularization_loss': 3.8659077,\n"," 'Loss/total_loss': 3.978824,\n"," 'learning_rate': 0.0319999}\n","I0208 10:55:22.955711 140571417827136 model_lib_v2.py:708] {'Loss/classification_loss': 0.093305096,\n"," 'Loss/localization_loss': 0.019611072,\n"," 'Loss/regularization_loss': 3.8659077,\n"," 'Loss/total_loss': 3.978824,\n"," 'learning_rate': 0.0319999}\n","INFO:tensorflow:Step 800 per-step time 1.829s\n","I0208 10:58:25.814909 140571417827136 model_lib_v2.py:705] Step 800 per-step time 1.829s\n","INFO:tensorflow:{'Loss/classification_loss': 0.1189367,\n"," 'Loss/localization_loss': 0.024627706,\n"," 'Loss/regularization_loss': 3.7657795,\n"," 'Loss/total_loss': 3.909344,\n"," 'learning_rate': 0.034666598}\n","I0208 10:58:25.815285 140571417827136 model_lib_v2.py:708] {'Loss/classification_loss': 0.1189367,\n"," 'Loss/localization_loss': 0.024627706,\n"," 'Loss/regularization_loss': 3.7657795,\n"," 'Loss/total_loss': 3.909344,\n"," 'learning_rate': 0.034666598}\n","INFO:tensorflow:Step 900 per-step time 1.834s\n","I0208 11:01:29.206786 140571417827136 model_lib_v2.py:705] Step 900 per-step time 1.834s\n","INFO:tensorflow:{'Loss/classification_loss': 0.092977054,\n"," 'Loss/localization_loss': 0.021845998,\n"," 'Loss/regularization_loss': 3.6605916,\n"," 'Loss/total_loss': 3.7754147,\n"," 'learning_rate': 0.037333302}\n","I0208 11:01:29.207189 140571417827136 model_lib_v2.py:708] {'Loss/classification_loss': 0.092977054,\n"," 'Loss/localization_loss': 0.021845998,\n"," 'Loss/regularization_loss': 3.6605916,\n"," 'Loss/total_loss': 3.7754147,\n"," 'learning_rate': 0.037333302}\n","INFO:tensorflow:Step 1000 per-step time 1.829s\n","I0208 11:04:32.103475 140571417827136 model_lib_v2.py:705] Step 1000 per-step time 1.829s\n","INFO:tensorflow:{'Loss/classification_loss': 0.0837797,\n"," 'Loss/localization_loss': 0.0134431645,\n"," 'Loss/regularization_loss': 3.5507672,\n"," 'Loss/total_loss': 3.64799,\n"," 'learning_rate': nan}\n","I0208 11:04:32.103906 140571417827136 model_lib_v2.py:708] {'Loss/classification_loss': 0.0837797,\n"," 'Loss/localization_loss': 0.0134431645,\n"," 'Loss/regularization_loss': 3.5507672,\n"," 'Loss/total_loss': 3.64799,\n"," 'learning_rate': nan}\n"]}]},{"cell_type":"code","source":["pwd"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"AhzchHZ2dcgl","executionInfo":{"status":"ok","timestamp":1675854452126,"user_tz":-330,"elapsed":601,"user":{"displayName":"Vishnu Karande","userId":"00058094659799713799"}},"outputId":"f2185cd0-ad16-4bc4-e898-414fd195774a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/traning_demo'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":38}]},{"cell_type":"code","source":["!python exporter_main_v2.py --input_type image_tensor --pipeline_config_path /content/traning_demo/models/my_ssd_resnet101_v1_fpn/pipeline.config --trained_checkpoint_dir /content/traning_demo/models/my_ssd_resnet101_v1_fpn --output_directory /content/traning_demo/exported-models/my_model"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j_A9dUmctYpv","executionInfo":{"status":"ok","timestamp":1675855549348,"user_tz":-330,"elapsed":93988,"user":{"displayName":"Vishnu Karande","userId":"00058094659799713799"}},"outputId":"3fca1fca-378e-4160-e27f-a3b9db95fccf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2023-02-08 11:24:16.055973: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n","2023-02-08 11:24:16.056075: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n","2023-02-08 11:24:16.056095: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n","2023-02-08 11:24:19.834430: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n","Instructions for updating:\n","Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n","W0208 11:24:19.973866 139663736145728 deprecation.py:350] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n","Instructions for updating:\n","Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n","WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py:458: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n","Instructions for updating:\n","back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n","Instead of:\n","results = tf.map_fn(fn, elems, back_prop=False)\n","Use:\n","results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n","W0208 11:24:20.084484 139663736145728 deprecation.py:623] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py:458: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n","Instructions for updating:\n","back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n","Instead of:\n","results = tf.map_fn(fn, elems, back_prop=False)\n","Use:\n","results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n","WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7f0570747910>, because it is not built.\n","W0208 11:24:49.651492 139663736145728 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7f0570747910>, because it is not built.\n","W0208 11:25:29.722190 139663736145728 save.py:271] Found untraced functions such as WeightSharedConvolutionalBoxPredictor_layer_call_fn, WeightSharedConvolutionalBoxPredictor_layer_call_and_return_conditional_losses, WeightSharedConvolutionalBoxHead_layer_call_fn, WeightSharedConvolutionalBoxHead_layer_call_and_return_conditional_losses, WeightSharedConvolutionalClassHead_layer_call_fn while saving (showing 5 of 329). These functions will not be directly callable after loading.\n","INFO:tensorflow:Assets written to: /content/traning_demo/exported-models/my_model/saved_model/assets\n","I0208 11:25:43.204884 139663736145728 builder_impl.py:797] Assets written to: /content/traning_demo/exported-models/my_model/saved_model/assets\n","INFO:tensorflow:Writing pipeline config file to /content/traning_demo/exported-models/my_model/pipeline.config\n","I0208 11:25:45.868452 139663736145728 config_util.py:253] Writing pipeline config file to /content/traning_demo/exported-models/my_model/pipeline.config\n"]}]},{"cell_type":"code","source":["import os\n","os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'    # Suppress TensorFlow logging (1)\n","import pathlib\n","import tensorflow as tf\n","import cv2\n","import argparse\n","from google.colab.patches import cv2_imshow\n","\n","# Enable GPU dynamic memory allocation\n","gpus = tf.config.experimental.list_physical_devices('GPU')\n","for gpu in gpus:\n","    tf.config.experimental.set_memory_growth(gpu, True)\n","\n","# PROVIDE PATH TO IMAGE DIRECTORY\n","IMAGE_PATHS = '/content/traning_demo/images/train/image16.jpg'\n","\n","\n","# PROVIDE PATH TO MODEL DIRECTORY\n","PATH_TO_MODEL_DIR = '/content/traning_demo/exported-models/my_model'\n","\n","# PROVIDE PATH TO LABEL MAP\n","PATH_TO_LABELS = '/content/traning_demo/annotations/label_map.pbtxt'\n","\n","# PROVIDE THE MINIMUM CONFIDENCE THRESHOLD\n","MIN_CONF_THRESH = float(0.60)\n","\n","# LOAD THE MODEL\n","\n","import time\n","from object_detection.utils import label_map_util\n","from object_detection.utils import visualization_utils as viz_utils\n","\n","PATH_TO_SAVED_MODEL = PATH_TO_MODEL_DIR + \"/saved_model\"\n","\n","print('Loading model...', end='')\n","start_time = time.time()\n","\n","# LOAD SAVED MODEL AND BUILD DETECTION FUNCTION\n","detect_fn = tf.saved_model.load(PATH_TO_SAVED_MODEL)\n","\n","end_time = time.time()\n","elapsed_time = end_time - start_time\n","print('Done! Took {} seconds'.format(elapsed_time))\n","\n","# LOAD LABEL MAP DATA FOR PLOTTING\n","\n","category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS,\n","                                                                    use_display_name=True)\n","\n","import numpy as np\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","import warnings\n","warnings.filterwarnings('ignore')   # Suppress Matplotlib warnings\n","\n","def load_image_into_numpy_array(path):\n","    \"\"\"Load an image from file into a numpy array.\n","    Puts image into numpy array to feed into tensorflow graph.\n","    Note that by convention we put it into a numpy array with shape\n","    (height, width, channels), where channels=3 for RGB.\n","    Args:\n","      path: the file path to the image\n","    Returns:\n","      uint8 numpy array with shape (img_height, img_width, 3)\n","    \"\"\"\n","    return np.array(Image.open(path))\n","\n","\n","\n","\n","print('Running inference for {}... '.format(IMAGE_PATHS), end='')\n","\n","image = cv2.imread(IMAGE_PATHS)\n","image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","image_expanded = np.expand_dims(image_rgb, axis=0)\n","\n","# The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n","input_tensor = tf.convert_to_tensor(image)\n","# The model expects a batch of images, so add an axis with `tf.newaxis`.\n","input_tensor = input_tensor[tf.newaxis, ...]\n","\n","# input_tensor = np.expand_dims(image_np, 0)\n","detections = detect_fn(input_tensor)\n","\n","# All outputs are batches tensors.\n","# Convert to numpy arrays, and take index [0] to remove the batch dimension.\n","# We're only interested in the first num_detections.\n","num_detections = int(detections.pop('num_detections'))\n","detections = {key: value[0, :num_detections].numpy()\n","               for key, value in detections.items()}\n","detections['num_detections'] = num_detections\n","\n","# detection_classes should be ints.\n","detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n","\n","image_with_detections = image.copy()\n","\n","# SET MIN_SCORE_THRESH BASED ON YOU MINIMUM THRESHOLD FOR DETECTIONS\n","viz_utils.visualize_boxes_and_labels_on_image_array(\n","      image_with_detections,\n","      detections['detection_boxes'],\n","      detections['detection_classes'],\n","      detections['detection_scores'],\n","      category_index,\n","      use_normalized_coordinates=True,\n","      max_boxes_to_draw=200,\n","      min_score_thresh=0.5,\n","      agnostic_mode=False)\n","\n","print('Done')\n","# DISPLAYS OUTPUT IMAGE\n","cv2_imshow(image_with_detections)\n","# CLOSES WINDOW ONCE KEY IS PRESSED\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"12RMXqds8jxG9ATVuE5Dhf2umID_8zhnD"},"id":"XjYp68qMvwMT","executionInfo":{"status":"ok","timestamp":1675858269408,"user_tz":-330,"elapsed":38675,"user":{"displayName":"Vishnu Karande","userId":"00058094659799713799"}},"outputId":"5fe25a5a-7d43-4b70-e2a9-5a9f9e21c37b"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":[],"metadata":{"id":"gXWcQT8pym6b"},"execution_count":null,"outputs":[]}]}